{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dota_ml.data import data_url, transform_data\n",
    "from dota_ml.utils import generate_grid, make_submission, plot_feature_ranking, plot_feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data/'):\n",
    "    !wget $data_url -q --show-progress\n",
    "    !tar -xvf data.tar.gz\n",
    "    !rm data.tar.gz\n",
    "else:\n",
    "    print('Data already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_params = {\n",
    "#     'scale': True,\n",
    "    \n",
    "#     'gold_features': True,\n",
    "#     'lh_features': True,\n",
    "#     'xp_features': True,\n",
    "    \n",
    "#     'heroes_by_player': True, \n",
    "#     'heroes_by_team': True,\n",
    "#     'vector_heroes': True,\n",
    "#     'bigram_heroes': True,\n",
    "    \n",
    "#     'events_features': True,\n",
    "    \n",
    "#     'items_by_player': True,\n",
    "#     'items_by_team': True,\n",
    "    'vector_items': True,\n",
    "    'bigram_items': True\n",
    "}\n",
    "\n",
    "train_df, test_df = transform_data(**data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop('radiant_won', axis=1)\n",
    "print('X_train.shape={}'.format(X_train.shape))\n",
    "\n",
    "y_train = train_df['radiant_won']\n",
    "print('y_train.shape={}'.format(y_train.shape))\n",
    "\n",
    "X_test = test_df\n",
    "print('X_test.shape={}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scoring = 'roc_auc'\n",
    "k_folds = 3\n",
    "\n",
    "estimator_param_grid = {\n",
    "    'max_iter': [1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [10 ** power for power in range(-2, 2 + 1)],\n",
    "    'verbose': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(LogisticRegression(), estimator_param_grid,\n",
    "                  scoring=scoring, cv=k_folds,\n",
    "                  refit=True, n_jobs=-1, verbose=5)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for score, std, params in zip(gs.cv_results_['mean_test_score'],\n",
    "                              gs.cv_results_['std_test_score'],\n",
    "                              gs.cv_results_['params']):\n",
    "    print('- score={:.5}, std={:.5} | params={}'.format(score, std, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score = gs.best_score_\n",
    "estimator = gs.best_estimator_\n",
    "estimator_params = gs.best_params_\n",
    "\n",
    "print('best_score: {}'.format(score))\n",
    "print('best params: {}'.format(estimator_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_submission(pd.DataFrame(X_test, index=test_df.index), estimator,\n",
    "                'submissions/', 'logreg', {**data_params, **estimator_params}, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if hasattr(X_test, 'columns'):\n",
    "    plot_feature_ranking(estimator.coef_.squeeze(), X_test.columns, max_n_importances=200)\n",
    "else:\n",
    "    print('features\\' column names are not avaliable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tf_env)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
