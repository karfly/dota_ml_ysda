{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dota_ml.data import DATA_URL, transform_data\n",
    "from dota_ml.utils import generate_grid, make_submission, plot_feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data/'):\n",
    "    !wget $DATA_URL -q --show-progress\n",
    "    !tar -xvf data.tar.gz\n",
    "else:\n",
    "    print('Data already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'last_gold_by_player': True, 'last_gold_by_team': True,\n",
    "    'gold_speed_by_player': True, 'gold_speed_by_team': True,\n",
    "    'max_gold_by_player': True, 'max_gold_by_team': True,\n",
    "    \n",
    "    'last_lh_by_player': True, 'last_lh_by_team': True,\n",
    "    'lh_speed_by_player': True, 'lh_speed_by_team': True,\n",
    "    'max_lh_by_player': True, 'max_lh_by_team': True,\n",
    "}\n",
    "\n",
    "train_df, test_df = transform_data('data/', **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop('radiant_won', axis=1)\n",
    "y_train = train_df['radiant_won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_param_grid = {\n",
    "    'n_estimators': [100, 1000, 5000],\n",
    "    'max_depth': [None, 2, 4, 6, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'min_samples_leaf': [1, 2, 5, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "\n",
    "    'random_state': [0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "scoring = 'roc_auc'\n",
    "k_folds = 3\n",
    "\n",
    "gs = RandomizedSearchCV(RandomForestClassifier(), model_param_grid,\n",
    "                        scoring=scoring, cv=k_folds, n_iter=n_iter,\n",
    "                        refit=True, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for score, std, params in zip(gs.cv_results_['mean_test_score'],\n",
    "                              gs.cv_results_['std_test_score'],\n",
    "                              gs.cv_results_['params']):\n",
    "    print('- score={:.5}, std={:.5} | params={}'.format(score, std, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_score = gs.best_score_\n",
    "best_estimator = gs.best_estimator_\n",
    "best_params = gs.best_params_\n",
    "\n",
    "print('best_score: {}'.format(best_score))\n",
    "print('best params: {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(test_df, best_estimator,\n",
    "                'submissions/', 'rfc', {**data_params, **best_params}, best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tf_env)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
